{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Value Imputation ,Word Segmentation , StopWords Removing\n",
    "### (Using Testing data for example, procedure here also applies to training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.font_manager import _rebuild\n",
    "\n",
    "_rebuild() #reload一下\n",
    "plt.rcParams['font.sans-serif']=['SimHei']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(\"test1.xlsx\", encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>title1_zh</th>\n",
       "      <th>title2_zh</th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>321187</td>\n",
       "      <td>167562</td>\n",
       "      <td>59521</td>\n",
       "      <td>萨拉赫人气爆棚!埃及总统大选未参选获百万选票 现任总统压力山大</td>\n",
       "      <td>辟谣！里昂官方否认费基尔加盟利物浦，难道是价格没谈拢？</td>\n",
       "      <td>egypt 's presidential election failed to win m...</td>\n",
       "      <td>Lyon! Lyon officials have denied that Felipe F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321190</td>\n",
       "      <td>167564</td>\n",
       "      <td>91315</td>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>10大最让美国人相信的荒诞谣言，如蜥蜴人掌控着美国</td>\n",
       "      <td>A message from Saddam Hussein after he was cap...</td>\n",
       "      <td>The Top 10 Americans believe that the Lizard M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>321189</td>\n",
       "      <td>167563</td>\n",
       "      <td>167564</td>\n",
       "      <td>萨达姆此项计划没有此国破坏的话，美国还会对伊拉克发动战争吗</td>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>Will the United States wage war on Iraq withou...</td>\n",
       "      <td>A message from Saddam Hussein after he was cap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>321193</td>\n",
       "      <td>167564</td>\n",
       "      <td>160994</td>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>被绞刑处死的萨达姆是替身？他的此男人举动击破替身谣言！</td>\n",
       "      <td>A message from Saddam Hussein after he was cap...</td>\n",
       "      <td>The hanging Saddam is a surrogate? This man's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321191</td>\n",
       "      <td>167564</td>\n",
       "      <td>15084</td>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>中国川贝枇杷膏在美国受到热捧？纯属谣言！</td>\n",
       "      <td>A message from Saddam Hussein after he was cap...</td>\n",
       "      <td>Chinese loquat loquat plaster in America? Pure...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    tid1    tid2                        title1_zh  \\\n",
       "0  321187  167562   59521  萨拉赫人气爆棚!埃及总统大选未参选获百万选票 现任总统压力山大   \n",
       "1  321190  167564   91315              萨达姆被捕后告诫美国的一句话，发人深思   \n",
       "2  321189  167563  167564    萨达姆此项计划没有此国破坏的话，美国还会对伊拉克发动战争吗   \n",
       "3  321193  167564  160994              萨达姆被捕后告诫美国的一句话，发人深思   \n",
       "4  321191  167564   15084              萨达姆被捕后告诫美国的一句话，发人深思   \n",
       "\n",
       "                     title2_zh  \\\n",
       "0  辟谣！里昂官方否认费基尔加盟利物浦，难道是价格没谈拢？   \n",
       "1    10大最让美国人相信的荒诞谣言，如蜥蜴人掌控着美国   \n",
       "2          萨达姆被捕后告诫美国的一句话，发人深思   \n",
       "3  被绞刑处死的萨达姆是替身？他的此男人举动击破替身谣言！   \n",
       "4         中国川贝枇杷膏在美国受到热捧？纯属谣言！   \n",
       "\n",
       "                                           title1_en  \\\n",
       "0  egypt 's presidential election failed to win m...   \n",
       "1  A message from Saddam Hussein after he was cap...   \n",
       "2  Will the United States wage war on Iraq withou...   \n",
       "3  A message from Saddam Hussein after he was cap...   \n",
       "4  A message from Saddam Hussein after he was cap...   \n",
       "\n",
       "                                           title2_en  \n",
       "0  Lyon! Lyon officials have denied that Felipe F...  \n",
       "1  The Top 10 Americans believe that the Lizard M...  \n",
       "2  A message from Saddam Hussein after he was cap...  \n",
       "3  The hanging Saddam is a surrogate? This man's ...  \n",
       "4  Chinese loquat loquat plaster in America? Pure...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80126, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title1_zh</th>\n",
       "      <th>title2_zh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>萨拉赫人气爆棚!埃及总统大选未参选获百万选票 现任总统压力山大</td>\n",
       "      <td>辟谣！里昂官方否认费基尔加盟利物浦，难道是价格没谈拢？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>10大最让美国人相信的荒诞谣言，如蜥蜴人掌控着美国</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>萨达姆此项计划没有此国破坏的话，美国还会对伊拉克发动战争吗</td>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title1_zh                    title2_zh\n",
       "0  萨拉赫人气爆棚!埃及总统大选未参选获百万选票 现任总统压力山大  辟谣！里昂官方否认费基尔加盟利物浦，难道是价格没谈拢？\n",
       "1              萨达姆被捕后告诫美国的一句话，发人深思    10大最让美国人相信的荒诞谣言，如蜥蜴人掌控着美国\n",
       "2    萨达姆此项计划没有此国破坏的话，美国还会对伊拉克发动战争吗          萨达姆被捕后告诫美国的一句话，发人深思"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['title1_zh','title2_zh']\n",
    "df1 = df1.loc[:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title1_zh    False\n",
       "title2_zh     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title1_zh    False\n",
       "title2_zh    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.title2_zh.fillna('UNKNOWN', inplace=True)\n",
    "df1.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded succeed\n"
     ]
    }
   ],
   "source": [
    "import thulac\n",
    "t=thulac.thulac()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thulac_tokenizer(text):\n",
    "    words = t.cut(text)\n",
    "    return ' '.join([word[0] for word in words if word[1] != 'w'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['UNKNOWN', 'x']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.cut('UNKNOWN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UNKNOWN'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thulac_tokenizer('UNKNOWN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-407635f9fd0a>:6: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert((data.index == res.index).all(), 'Something error when merge data')\n"
     ]
    }
   ],
   "source": [
    "def process(data):\n",
    "    res = data.apply(thulac_tokenizer)\n",
    "    return res\n",
    "\n",
    "def check_merge_idx(data, res):\n",
    "    assert((data.index == res.index).all(), 'Something error when merge data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "for i,string in enumerate(df1.loc[:, 'title2_zh']):\n",
    "    if isinstance(string,list):\n",
    "        print(i,string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(df1.index == df1.title1_zh.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import fool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize data\n",
    "df1['title2_tokenized'] = process(df1.loc[:, 'title2_zh'])\n",
    "df1['title1_tokenized'] = process(df1.loc[:, 'title1_zh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name entity recognition \n",
    "df1['title1_ner']=df1['title1_zh'].apply(fool.ner)\n",
    "df1['title2_ner']=df1['title2_zh'].apply(fool.ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn string to list\n",
    "df1['title1_tokenized']=df1['title1_tokenized'].apply(lambda x: x.split(' '))\n",
    "df1['title2_tokenized']=df1['title2_tokenized'].apply(lambda x: x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title1_zh</th>\n",
       "      <th>title2_zh</th>\n",
       "      <th>title2_tokenized</th>\n",
       "      <th>title1_tokenized</th>\n",
       "      <th>title1_ner</th>\n",
       "      <th>title2_ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>萨拉赫人气爆棚!埃及总统大选未参选获百万选票 现任总统压力山大</td>\n",
       "      <td>辟谣！里昂官方否认费基尔加盟利物浦，难道是价格没谈拢？</td>\n",
       "      <td>[辟谣, 里昂, 官方, 否, 认费, 基尔, 加盟, 利物浦, 难道, 是, 价, 格没,...</td>\n",
       "      <td>[萨拉赫, 人气, 爆棚, 埃及, 总统, 大选, 未, 参选, 获, 百万, 选票, , ...</td>\n",
       "      <td>[[(0, 4, person, 萨拉赫), (10, 13, job, 总统), (25,...</td>\n",
       "      <td>[[(9, 18, location, 费基尔加盟利物浦)]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>10大最让美国人相信的荒诞谣言，如蜥蜴人掌控着美国</td>\n",
       "      <td>[10, 大, 最, 让, 美国, 人, 相信, 的, 荒诞, 谣言, 如, 蜥蜴人, 掌控...</td>\n",
       "      <td>[萨达姆, 被捕, 后, 告诫, 美国, 的, 一, 句, 话, 发人深思]</td>\n",
       "      <td>[[(0, 4, person, 萨达姆), (8, 11, location, 美国)]]</td>\n",
       "      <td>[[(5, 8, location, 美国), (23, 26, location, 美国)]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>萨达姆此项计划没有此国破坏的话，美国还会对伊拉克发动战争吗</td>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>[萨达姆, 被捕, 后, 告诫, 美国, 的, 一, 句, 话, 发人深思]</td>\n",
       "      <td>[萨达姆, 此, 项, 计划, 没有, 此国, 破坏, 的, 话, 美国, 还, 会, 对,...</td>\n",
       "      <td>[[(0, 4, person, 萨达姆), (16, 19, location, 美国),...</td>\n",
       "      <td>[[(0, 4, person, 萨达姆), (8, 11, location, 美国)]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>被绞刑处死的萨达姆是替身？他的此男人举动击破替身谣言！</td>\n",
       "      <td>[被, 绞刑, 处死, 的, 萨达姆, 是, 替身, 他, 的, 此, 男人, 举动, 击破...</td>\n",
       "      <td>[萨达姆, 被捕, 后, 告诫, 美国, 的, 一, 句, 话, 发人深思]</td>\n",
       "      <td>[[(0, 4, person, 萨达姆), (8, 11, location, 美国)]]</td>\n",
       "      <td>[[(6, 10, person, 萨达姆)]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>中国川贝枇杷膏在美国受到热捧？纯属谣言！</td>\n",
       "      <td>[中国, 川贝, 枇杷膏, 在, 美国, 受到, 热捧, 纯属, 谣言]</td>\n",
       "      <td>[萨达姆, 被捕, 后, 告诫, 美国, 的, 一, 句, 话, 发人深思]</td>\n",
       "      <td>[[(0, 4, person, 萨达姆), (8, 11, location, 美国)]]</td>\n",
       "      <td>[[(0, 3, location, 中国), (8, 11, location, 美国)]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title1_zh                    title2_zh  \\\n",
       "0  萨拉赫人气爆棚!埃及总统大选未参选获百万选票 现任总统压力山大  辟谣！里昂官方否认费基尔加盟利物浦，难道是价格没谈拢？   \n",
       "1              萨达姆被捕后告诫美国的一句话，发人深思    10大最让美国人相信的荒诞谣言，如蜥蜴人掌控着美国   \n",
       "2    萨达姆此项计划没有此国破坏的话，美国还会对伊拉克发动战争吗          萨达姆被捕后告诫美国的一句话，发人深思   \n",
       "3              萨达姆被捕后告诫美国的一句话，发人深思  被绞刑处死的萨达姆是替身？他的此男人举动击破替身谣言！   \n",
       "4              萨达姆被捕后告诫美国的一句话，发人深思         中国川贝枇杷膏在美国受到热捧？纯属谣言！   \n",
       "\n",
       "                                    title2_tokenized  \\\n",
       "0  [辟谣, 里昂, 官方, 否, 认费, 基尔, 加盟, 利物浦, 难道, 是, 价, 格没,...   \n",
       "1  [10, 大, 最, 让, 美国, 人, 相信, 的, 荒诞, 谣言, 如, 蜥蜴人, 掌控...   \n",
       "2             [萨达姆, 被捕, 后, 告诫, 美国, 的, 一, 句, 话, 发人深思]   \n",
       "3  [被, 绞刑, 处死, 的, 萨达姆, 是, 替身, 他, 的, 此, 男人, 举动, 击破...   \n",
       "4               [中国, 川贝, 枇杷膏, 在, 美国, 受到, 热捧, 纯属, 谣言]   \n",
       "\n",
       "                                    title1_tokenized  \\\n",
       "0  [萨拉赫, 人气, 爆棚, 埃及, 总统, 大选, 未, 参选, 获, 百万, 选票, , ...   \n",
       "1             [萨达姆, 被捕, 后, 告诫, 美国, 的, 一, 句, 话, 发人深思]   \n",
       "2  [萨达姆, 此, 项, 计划, 没有, 此国, 破坏, 的, 话, 美国, 还, 会, 对,...   \n",
       "3             [萨达姆, 被捕, 后, 告诫, 美国, 的, 一, 句, 话, 发人深思]   \n",
       "4             [萨达姆, 被捕, 后, 告诫, 美国, 的, 一, 句, 话, 发人深思]   \n",
       "\n",
       "                                          title1_ner  \\\n",
       "0  [[(0, 4, person, 萨拉赫), (10, 13, job, 总统), (25,...   \n",
       "1     [[(0, 4, person, 萨达姆), (8, 11, location, 美国)]]   \n",
       "2  [[(0, 4, person, 萨达姆), (16, 19, location, 美国),...   \n",
       "3     [[(0, 4, person, 萨达姆), (8, 11, location, 美国)]]   \n",
       "4     [[(0, 4, person, 萨达姆), (8, 11, location, 美国)]]   \n",
       "\n",
       "                                         title2_ner  \n",
       "0                   [[(9, 18, location, 费基尔加盟利物浦)]]  \n",
       "1  [[(5, 8, location, 美国), (23, 26, location, 美国)]]  \n",
       "2    [[(0, 4, person, 萨达姆), (8, 11, location, 美国)]]  \n",
       "3                          [[(6, 10, person, 萨达姆)]]  \n",
       "4   [[(0, 3, location, 中国), (8, 11, location, 美国)]]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You should download Chinese Stopwords first and save it in the location as your codes\n",
    "stopWords=[]\n",
    "with open('chnstopwords.txt', 'r', encoding='UTF-8') as file:\n",
    "    for data in file.readlines():\n",
    "        data = data.strip()\n",
    "        stopWords.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "746"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterstop(sentence):\n",
    "    ls=[]\n",
    "    for word in sentence:\n",
    "        if word not in stopWords:\n",
    "            ls.append(word)\n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Stopwords\n",
    "df1['title1_tokenized']=df1['title1_tokenized'].apply(filterstop)\n",
    "df1['title2_tokenized']=df1['title2_tokenized'].apply(filterstop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title1_zh</th>\n",
       "      <th>title2_zh</th>\n",
       "      <th>title2_tokenized</th>\n",
       "      <th>title1_tokenized</th>\n",
       "      <th>title1_ner</th>\n",
       "      <th>title2_ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>萨拉赫人气爆棚!埃及总统大选未参选获百万选票 现任总统压力山大</td>\n",
       "      <td>辟谣！里昂官方否认费基尔加盟利物浦，难道是价格没谈拢？</td>\n",
       "      <td>[辟谣, 里昂, 官方, 否, 认费, 基尔, 加盟, 利物浦, 难道, 价, 格没, 谈拢]</td>\n",
       "      <td>[萨拉赫, 人气, 爆棚, 埃及, 总统, 大选, 未, 参选, 获, 百万, 选票, , ...</td>\n",
       "      <td>[[(0, 4, person, 萨拉赫), (10, 13, job, 总统), (25,...</td>\n",
       "      <td>[[(9, 18, location, 费基尔加盟利物浦)]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>10大最让美国人相信的荒诞谣言，如蜥蜴人掌控着美国</td>\n",
       "      <td>[10, 美国, 相信, 荒诞, 谣言, 蜥蜴人, 掌控, 美国]</td>\n",
       "      <td>[萨达姆, 被捕, 告诫, 美国, 句, 话, 发人深思]</td>\n",
       "      <td>[[(0, 4, person, 萨达姆), (8, 11, location, 美国)]]</td>\n",
       "      <td>[[(5, 8, location, 美国), (23, 26, location, 美国)]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>萨达姆此项计划没有此国破坏的话，美国还会对伊拉克发动战争吗</td>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>[萨达姆, 被捕, 告诫, 美国, 句, 话, 发人深思]</td>\n",
       "      <td>[萨达姆, 项, 计划, 没有, 此国, 破坏, 话, 美国, 会, 伊拉克, 发动, 战争]</td>\n",
       "      <td>[[(0, 4, person, 萨达姆), (16, 19, location, 美国),...</td>\n",
       "      <td>[[(0, 4, person, 萨达姆), (8, 11, location, 美国)]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>被绞刑处死的萨达姆是替身？他的此男人举动击破替身谣言！</td>\n",
       "      <td>[绞刑, 处死, 萨达姆, 替身, 男人, 举动, 击破, 替身, 谣言]</td>\n",
       "      <td>[萨达姆, 被捕, 告诫, 美国, 句, 话, 发人深思]</td>\n",
       "      <td>[[(0, 4, person, 萨达姆), (8, 11, location, 美国)]]</td>\n",
       "      <td>[[(6, 10, person, 萨达姆)]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>中国川贝枇杷膏在美国受到热捧？纯属谣言！</td>\n",
       "      <td>[中国, 川贝, 枇杷膏, 美国, 热捧, 纯属, 谣言]</td>\n",
       "      <td>[萨达姆, 被捕, 告诫, 美国, 句, 话, 发人深思]</td>\n",
       "      <td>[[(0, 4, person, 萨达姆), (8, 11, location, 美国)]]</td>\n",
       "      <td>[[(0, 3, location, 中国), (8, 11, location, 美国)]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title1_zh                    title2_zh  \\\n",
       "0  萨拉赫人气爆棚!埃及总统大选未参选获百万选票 现任总统压力山大  辟谣！里昂官方否认费基尔加盟利物浦，难道是价格没谈拢？   \n",
       "1              萨达姆被捕后告诫美国的一句话，发人深思    10大最让美国人相信的荒诞谣言，如蜥蜴人掌控着美国   \n",
       "2    萨达姆此项计划没有此国破坏的话，美国还会对伊拉克发动战争吗          萨达姆被捕后告诫美国的一句话，发人深思   \n",
       "3              萨达姆被捕后告诫美国的一句话，发人深思  被绞刑处死的萨达姆是替身？他的此男人举动击破替身谣言！   \n",
       "4              萨达姆被捕后告诫美国的一句话，发人深思         中国川贝枇杷膏在美国受到热捧？纯属谣言！   \n",
       "\n",
       "                                  title2_tokenized  \\\n",
       "0  [辟谣, 里昂, 官方, 否, 认费, 基尔, 加盟, 利物浦, 难道, 价, 格没, 谈拢]   \n",
       "1                [10, 美国, 相信, 荒诞, 谣言, 蜥蜴人, 掌控, 美国]   \n",
       "2                    [萨达姆, 被捕, 告诫, 美国, 句, 话, 发人深思]   \n",
       "3            [绞刑, 处死, 萨达姆, 替身, 男人, 举动, 击破, 替身, 谣言]   \n",
       "4                    [中国, 川贝, 枇杷膏, 美国, 热捧, 纯属, 谣言]   \n",
       "\n",
       "                                    title1_tokenized  \\\n",
       "0  [萨拉赫, 人气, 爆棚, 埃及, 总统, 大选, 未, 参选, 获, 百万, 选票, , ...   \n",
       "1                      [萨达姆, 被捕, 告诫, 美国, 句, 话, 发人深思]   \n",
       "2    [萨达姆, 项, 计划, 没有, 此国, 破坏, 话, 美国, 会, 伊拉克, 发动, 战争]   \n",
       "3                      [萨达姆, 被捕, 告诫, 美国, 句, 话, 发人深思]   \n",
       "4                      [萨达姆, 被捕, 告诫, 美国, 句, 话, 发人深思]   \n",
       "\n",
       "                                          title1_ner  \\\n",
       "0  [[(0, 4, person, 萨拉赫), (10, 13, job, 总统), (25,...   \n",
       "1     [[(0, 4, person, 萨达姆), (8, 11, location, 美国)]]   \n",
       "2  [[(0, 4, person, 萨达姆), (16, 19, location, 美国),...   \n",
       "3     [[(0, 4, person, 萨达姆), (8, 11, location, 美国)]]   \n",
       "4     [[(0, 4, person, 萨达姆), (8, 11, location, 美国)]]   \n",
       "\n",
       "                                         title2_ner  \n",
       "0                   [[(9, 18, location, 费基尔加盟利物浦)]]  \n",
       "1  [[(5, 8, location, 美国), (23, 26, location, 美国)]]  \n",
       "2    [[(0, 4, person, 萨达姆), (8, 11, location, 美国)]]  \n",
       "3                          [[(6, 10, person, 萨达姆)]]  \n",
       "4   [[(0, 3, location, 中国), (8, 11, location, 美国)]]  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Useful Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Absolute Diffence of length of words in title1 and title2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['lenword']=abs(df1['title1_tokenized'].apply(len)-df1['title2_tokenized'].apply(len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Absolute Diffence of length of characters in title1 and title2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['lenchar']=abs(df1['title1_zh'].apply(len)-df1['title2_zh'].apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.       , 0.6721087],\n",
       "       [0.6721087, 1.       ]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(df1['lenchar'],df1['lenword'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.Number of words shared in title1 and title2 (repetition counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2): \n",
    "    lst3 = [value for value in lst1 if value in lst2] \n",
    "    return len(lst3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['wordmatch']=df1.apply(lambda row:intersection(row['title1_tokenized'],row['title2_tokenized']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.Number of words in title2 but not in title 1 (repetition counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypextrals(lst1, lst2): \n",
    "    lst3 = [value for value in lst2 if value not in lst1] \n",
    "    return len(lst3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['hypextra']=df1.apply(lambda row:hypextrals(row['title1_tokenized'],row['title2_tokenized'),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.62793109],\n",
       "       [-0.62793109,  1.        ]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(df1['wordmatch'],df1['hypextra'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove position information in name entity recognition\n",
    "def nonumner(sent):\n",
    "    s=[]\n",
    "    for word in sent[0]:\n",
    "        s.append(word[-2:])\n",
    "    return s    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('person', '萨达姆'), ('location', '美国')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "nonumner(df1.loc[2,'title2_ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['title1_nonumner']=df1['title1_ner'].apply(nonumner)\n",
    "df1['title2_nonumner']=df1['title2_ner'].apply(nonumner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.Number of NERs shared in title1 and title2 (repetition counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['nerwordmatch']=df1.apply(lambda row:intersection(row['title1_nonumner'],row['title2_nonumner']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    54011\n",
       "1    16223\n",
       "2     7451\n",
       "3     2039\n",
       "4      369\n",
       "5       32\n",
       "6        1\n",
       "Name: nerwordmatch, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['nerwordmatch'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.Number of NERs in title2 but not in title 1 (repetition counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['nerhypextra']=df1.apply(lambda row:hypextrals(row['title1_nonumner'],row['title2_nonumner']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     44021\n",
       "1     24147\n",
       "2      8825\n",
       "3      2411\n",
       "4       604\n",
       "5        94\n",
       "6        19\n",
       "7         4\n",
       "10        1\n",
       "Name: nerhypextra, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['nerhypextra'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.11706049],\n",
       "       [-0.11706049,  1.        ]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(df1['nerwordmatch'],df1['nerhypextra'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You need to download one of the Chinese fonts to your local drive first to display the chinese character in the plot,here I download Simhei Font\n",
    "font = r'C:\\Users\\user\\Anaconda3\\pkgs\\matplotlib-2.2.2-py36h153e9ff_1\\Lib\\site-packages\\matplotlib\\mpl-data\\fonts\\ttf\\SimHei.ttf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qsdis =df1.loc[df1['label'] == 'disagreed','title2_zh'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examine which word appears most frequently in title2\n",
    "cloud = WordCloud(width=1440, height=1080, font_path=font).generate(\" \".join(train_qsdis.astype(str)))\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.imshow(cloud)\n",
    "plt.axis('off')\n",
    "cloud.to_file('show_Chinese.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose seven key words appear most frequently in title2\n",
    "def iscontentword(word):\n",
    "     return word in ('辟谣','网传','谣言','假的','假消息','网警','警方')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(filter(iscontentword,['辟谣','网传','谣言','假的','假的','我'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.Number of key words appear in title2 (repetition counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['iskey']=df1['title2_tokenized'].apply(lambda x:len(list(filter(iscontentword,x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.iskey.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the processed data to local drive for future analyzation\n",
    "df1.to_csv('datatestsplattrs.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}